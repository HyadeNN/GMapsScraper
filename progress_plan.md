# Google Maps Scraper - Web UI Development Plan

## ğŸ“‹ Project Overview

This document outlines the comprehensive plan for developing a modern web-based UI for the Google Maps Scraper application. The UI will replace CLI-based operations with an intuitive web interface built using FastAPI (backend) and React (frontend).

### Current Project State
- **Existing Backend**: Python scraper using Google Places API (New)
- **Current Interface**: CLI-based with argparse
- **Data Format**: locationsV2.json with nested city/district structure
- **API**: Recently migrated from Legacy to New Google Places API (Pro tier)
- **Features**: Standard search, grid search, batch processing, multiple output formats

## ğŸ¯ Goals & Requirements

### Primary Goals
1. **Replace CLI with Web UI**: Modern, user-friendly interface
2. **Flexible Location Selection**: Tree-based city/district selection with granular control
3. **Multiple Search Methods**: Standard, grid search, and skip options per location
4. **Real-time Progress**: Live updates during scraping operations
5. **Profile Management**: Save/load search configurations
6. **Settings Integration**: All settings.py variables configurable via UI

### User Experience Requirements
- **Tree View**: Collapsible hierarchical location selection
- **Batch Operations**: Quick selection of multiple locations
- **Progress Tracking**: Detailed progress with ETA, current location, and live logs
- **Profile System**: Save configurations as named profiles with auto-save
- **Responsive Design**: Works on desktop and tablet devices

## ğŸ—ï¸ Technical Architecture

### Tech Stack
- **Backend**: FastAPI (Python 3.11+)
- **Frontend**: React 18+ with modern hooks
- **Communication**: REST API + WebSocket for real-time updates
- **Data Storage**: JSON files for profiles, existing infrastructure for results
- **UI Framework**: Material-UI or Ant Design for professional appearance

### Project Structure
```
web_ui/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                    # FastAPI application entry point
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ locations.py       # Location data endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper.py         # Scraping control endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ profiles.py        # Profile management endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py        # Settings management endpoints
â”‚   â”‚   â”‚   â””â”€â”€ websocket.py       # Real-time communication
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ location.py        # Location selection models
â”‚   â”‚       â”œâ”€â”€ scraper.py         # Scraper configuration models
â”‚   â”‚       â”œâ”€â”€ profile.py         # Profile data models
â”‚   â”‚       â””â”€â”€ settings.py        # Settings models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ scraper_service.py     # Integration with existing scraper
â”‚   â”‚   â”œâ”€â”€ profile_service.py     # Profile CRUD operations
â”‚   â”‚   â”œâ”€â”€ location_service.py    # Location data management
â”‚   â”‚   â””â”€â”€ websocket_service.py   # WebSocket message handling
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ integration.py         # Integration with existing gmaps_scraper
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â””â”€â”€ favicon.ico
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ LocationTree/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LocationTree.jsx    # Main tree component
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ CityNode.jsx        # City-level tree node
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DistrictNode.jsx    # District-level tree node
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ LocationTree.css    # Tree styling
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigPanel/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SettingsPanel.jsx   # API settings configuration
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SearchOptions.jsx   # Search method selection
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ BatchOperations.jsx # Bulk selection tools
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ConfigPanel.css     # Panel styling
â”‚   â”‚   â”‚   â”œâ”€â”€ ProgressPanel/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProgressOverview.jsx # Progress statistics
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LiveLog.jsx         # Real-time log display
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ResultsPreview.jsx  # Results summary
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ProgressPanel.css   # Progress styling
â”‚   â”‚   â”‚   â”œâ”€â”€ ProfileManager/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProfileSelector.jsx # Profile dropdown/list
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProfileEditor.jsx   # Profile creation/editing
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ProfileManager.css  # Profile styling
â”‚   â”‚   â”‚   â””â”€â”€ Layout/
â”‚   â”‚   â”‚       â”œâ”€â”€ Header.jsx          # App header with controls
â”‚   â”‚   â”‚       â”œâ”€â”€ MainLayout.jsx      # 3-panel layout
â”‚   â”‚   â”‚       â””â”€â”€ Layout.css          # Layout styling
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useWebSocket.js         # WebSocket communication
â”‚   â”‚   â”‚   â”œâ”€â”€ useSettings.js          # Settings state management
â”‚   â”‚   â”‚   â”œâ”€â”€ useLocations.js         # Location selection state
â”‚   â”‚   â”‚   â”œâ”€â”€ useProfiles.js          # Profile management
â”‚   â”‚   â”‚   â””â”€â”€ useScraper.js           # Scraper control state
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.js                  # API client configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ locationService.js      # Location API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ scraperService.js       # Scraper API calls
â”‚   â”‚   â”‚   â”œâ”€â”€ profileService.js       # Profile API calls
â”‚   â”‚   â”‚   â””â”€â”€ settingsService.js      # Settings API calls
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ constants.js            # App constants
â”‚   â”‚   â”‚   â””â”€â”€ helpers.js              # Utility functions
â”‚   â”‚   â”œâ”€â”€ App.jsx                     # Main application component
â”‚   â”‚   â”œâ”€â”€ App.css                     # Global styling
â”‚   â”‚   â””â”€â”€ index.js                    # React entry point
â”‚   â”œâ”€â”€ package.json                    # NPM dependencies
â”‚   â””â”€â”€ package-lock.json
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ docker-compose.yml                  # Optional containerization
â””â”€â”€ README.md                          # Setup and usage instructions
```

## ğŸ“Š Data Models

### Location Configuration Model
```python
class SearchMethod(str, Enum):
    SKIP = "skip"
    STANDARD = "standard"
    GRID = "grid"

class DistrictConfig(BaseModel):
    name: str
    coordinates: Tuple[float, float]  # (lat, lng)
    selected: bool = False
    search_method: SearchMethod = SearchMethod.STANDARD

class CityConfig(BaseModel):
    name: str
    coordinates: Tuple[float, float]  # (lat, lng)
    selected: bool = False
    search_method: SearchMethod = SearchMethod.SKIP
    city_level_search: bool = True  # Whether to search at city level
    districts: Dict[str, DistrictConfig] = {}

class LocationSelection(BaseModel):
    cities: Dict[str, CityConfig]
    total_selected: int = 0
    estimated_duration: Optional[str] = None
```

### Scraper Settings Model
```python
class ScraperSettings(BaseModel):
    api_key: str
    search_terms: List[str] = ["diÅŸ kliniÄŸi", "dentist"]
    default_radius: int = 15000  # meters
    request_delay: float = 1.0  # seconds
    max_retries: int = 3
    batch_size: int = 20
    storage_type: Literal["json", "mongodb"] = "json"
    output_directory: str = "data"
    
    # Grid search specific settings
    grid_width_km: float = 5.0
    grid_height_km: float = 5.0
    grid_radius_meters: int = 800
    
    # UI specific settings
    auto_save_interval: int = 2  # seconds
    log_level: str = "INFO"
```

### Profile Model
```python
class ScrapingProfile(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid4()))
    name: str
    description: Optional[str] = None
    settings: ScraperSettings
    locations: LocationSelection
    created_at: datetime = Field(default_factory=datetime.now)
    last_used: Optional[datetime] = None
    is_default: bool = False

class ProfileListResponse(BaseModel):
    profiles: List[ScrapingProfile]
    default_profile_id: Optional[str] = None
```

### Progress Model
```python
class ProgressStatus(str, Enum):
    IDLE = "idle"
    RUNNING = "running"
    PAUSED = "paused"
    COMPLETED = "completed"
    ERROR = "error"

class CurrentProgress(BaseModel):
    status: ProgressStatus = ProgressStatus.IDLE
    current_city: Optional[str] = None
    current_district: Optional[str] = None
    completed_locations: int = 0
    total_locations: int = 0
    completion_percentage: float = 0.0
    estimated_time_remaining: Optional[str] = None
    processing_speed: Optional[str] = None  # "2.3 locations/min"
    results_found: int = 0
    errors_encountered: int = 0
    last_save_time: Optional[datetime] = None
    start_time: Optional[datetime] = None

class LogMessage(BaseModel):
    timestamp: datetime = Field(default_factory=datetime.now)
    level: str  # DEBUG, INFO, WARNING, ERROR
    message: str
    location: Optional[str] = None  # "Ä°stanbul/KadÄ±kÃ¶y"
```

## ğŸ¨ User Interface Design

### Layout Structure (3-Panel Design)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Header: API Status | Profile Selector | Start/Stop/Pause Controls           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Left Panel    â”‚      Center Panel       â”‚          Right Panel            â”‚
â”‚   (320px)       â”‚       (flex-1)          â”‚           (380px)               â”‚
â”‚                 â”‚                         â”‚                                 â”‚
â”‚ ğŸŒ³ Location     â”‚  âš™ï¸ Settings Panel     â”‚  ğŸ“Š Progress Dashboard          â”‚
â”‚    Tree         â”‚                         â”‚                                 â”‚
â”‚                 â”‚  ğŸ”‘ API Configuration   â”‚  ğŸ“ Current Location:           â”‚
â”‚ ğŸ‡¹ğŸ‡· TÃ¼rkiye     â”‚  â€¢ API Key              â”‚     Ä°stanbul / KadÄ±kÃ¶y          â”‚
â”‚  â”œğŸ“ Ä°stanbul   â”‚  â€¢ Search Terms         â”‚                                 â”‚
â”‚  â”‚ ğŸ¯ City [âš«]  â”‚  â€¢ Default Radius       â”‚  ğŸ“ˆ Progress: 23/156 (14.7%)   â”‚
â”‚  â”‚ â”œğŸ˜ï¸ KadÄ±kÃ¶y  â”‚                         â”‚  â±ï¸ ETA: 45 minutes             â”‚
â”‚  â”‚ â”œğŸ˜ï¸ BeÅŸiktaÅŸ â”‚  ğŸ”§ Search Configuration â”‚  ğŸš€ Speed: 2.3 locations/min   â”‚
â”‚  â”‚ â””ğŸ˜ï¸ ÃœskÃ¼dar  â”‚  â€¢ Request Delay        â”‚  ğŸ“Š Results: 1,247 places      â”‚
â”‚  â”œğŸ“ Ankara     â”‚  â€¢ Batch Size           â”‚  âŒ Errors: 2                   â”‚
â”‚  â”‚ ğŸ¯ City [â˜]  â”‚  â€¢ Grid Settings        â”‚                                 â”‚
â”‚  â””ğŸ“ Ä°zmir      â”‚                         â”‚  ğŸ“ Live Log                    â”‚
â”‚  â”‚ ğŸ¯ City [â˜‘ï¸]  â”‚  âš¡ Batch Operations    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                 â”‚  â€¢ Select: Major Cities â”‚  â”‚ [10:30:15] Ä°stanbul/KadÄ±kÃ¶y â”‚ â”‚
â”‚ ğŸ’¾ Profiles     â”‚  â€¢ Apply: Grid Search   â”‚  â”‚ search started...           â”‚ â”‚
â”‚ â€¢ ğŸ¢ Major Citiesâ”‚  â€¢ Apply: Standard      â”‚  â”‚ [10:30:23] Found 15 results â”‚ â”‚
â”‚ â€¢ ğŸŒ All Turkey â”‚  â€¢ Clear: All Selection â”‚  â”‚ [10:30:31] Batch saved      â”‚ â”‚
â”‚ â€¢ ğŸ“ Custom 1   â”‚                         â”‚  â”‚ [10:30:35] Moving to next   â”‚ â”‚
â”‚ â€¢ â• New Profileâ”‚                         â”‚  â”‚ location...                 â”‚ â”‚
â”‚                 â”‚                         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Tree View Component Features

#### Checkbox States and Behavior
- **â˜‘ï¸ Checked**: Location is selected for scraping
- **â˜ Unchecked**: Location will be skipped
- **âš« Mixed**: Some child locations are selected, some are not

#### Search Method Indicators
- **ğŸ¯ City Level**: Indicates city-level search is enabled
- **ğŸ“ Standard**: Standard radius search
- **ğŸ”§ Grid**: Grid search method
- **â­ï¸ Skip**: Location will be skipped

#### Context Menu (Right-click)
```
Right-click Menu Options:
â”œâ”€â”€ âœ… Select All Sublocation
â”œâ”€â”€ âŒ Deselect All Sublocations
â”œâ”€â”€ ğŸ“ Set All to Standard Search
â”œâ”€â”€ ğŸ”§ Set All to Grid Search
â”œâ”€â”€ â­ï¸ Set All to Skip
â”œâ”€â”€ ğŸ“‹ Copy Configuration
â”œâ”€â”€ ğŸ“„ Paste Configuration
â””â”€â”€ ğŸ“Š Estimate Duration
```

#### Keyboard Shortcuts
- **Space**: Toggle selection
- **Ctrl+A**: Select all visible items
- **Ctrl+Shift+A**: Deselect all
- **Enter**: Expand/collapse node
- **Delete**: Set to skip

### Settings Panel Features

#### API Configuration Section
```
ğŸ”‘ API Configuration
â”œâ”€â”€ API Key: [â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢] [Test Connection]
â”œâ”€â”€ Language: [Turkish â–¼] 
â”œâ”€â”€ Region: [Turkey â–¼]
â””â”€â”€ Rate Limiting: [1.0 sec delay] [3 max retries]
```

#### Search Configuration Section
```
ğŸ” Search Configuration  
â”œâ”€â”€ Search Terms: [diÅŸ kliniÄŸi] [+ Add Term]
â”œâ”€â”€ Default Radius: [15,000 meters] [â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€]
â”œâ”€â”€ Batch Size: [20 places] [â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€]
â””â”€â”€ Output Directory: [data/] [Browse...]
```

#### Grid Search Settings
```
ğŸ”§ Grid Search Settings
â”œâ”€â”€ Grid Dimensions: [5.0 km] Ã— [5.0 km]
â”œâ”€â”€ Point Radius: [800 meters] [â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€]
â”œâ”€â”€ Overlap Factor: [1.5x] (Auto-calculated)
â””â”€â”€ Estimated Points: ~25 points per grid
```

### Batch Operations Panel

#### Smart Selection Presets
```javascript
const smartSelections = [
  { 
    id: 'major-cities', 
    label: 'Major Cities (15)', 
    description: 'Ä°stanbul, Ankara, Ä°zmir, Bursa, Antalya...',
    cities: ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', 'Antalya', ...]
  },
  { 
    id: 'coastal-cities', 
    label: 'Coastal Cities (22)', 
    description: 'Cities with coastline access',
    cities: ['Ä°stanbul', 'Ä°zmir', 'Antalya', 'Mersin', ...]
  },
  { 
    id: 'central-anatolia', 
    label: 'Central Anatolia (13)', 
    description: 'Inner Anatolia region cities',
    cities: ['Ankara', 'Konya', 'Kayseri', 'Sivas', ...]
  },
  { 
    id: 'metro-areas', 
    label: 'Metropolitan Areas (8)', 
    description: 'Cities with metro systems',
    cities: ['Ä°stanbul', 'Ankara', 'Ä°zmir', 'Bursa', ...]
  }
]
```

#### Mass Action Buttons
```
âš¡ Mass Actions
â”œâ”€â”€ ğŸ“ Set Selected â†’ Standard Search
â”œâ”€â”€ ğŸ”§ Set Selected â†’ Grid Search  
â”œâ”€â”€ ğŸ¯ Enable City-Level Search
â”œâ”€â”€ â­ï¸ Disable City-Level Search
â”œâ”€â”€ ğŸ”„ Invert Selection
â”œâ”€â”€ âŒ Clear All Selections
â””â”€â”€ ğŸ“Š Calculate Total Duration
```

## ğŸ”„ Real-time Communication

### WebSocket Events

#### Client to Server Events
```python
class WSClientMessage(BaseModel):
    type: Literal[
        "start_scraping",
        "pause_scraping", 
        "stop_scraping",
        "get_progress",
        "subscribe_logs"
    ]
    data: Optional[Dict] = None

# Example usage:
{
  "type": "start_scraping",
  "data": {
    "profile_id": "uuid-here",
    "settings": {...},
    "locations": {...}
  }
}
```

#### Server to Client Events
```python
class WSServerMessage(BaseModel):
    type: Literal[
        "progress_update",
        "log_message", 
        "scraping_started",
        "scraping_completed",
        "scraping_paused",
        "scraping_error",
        "location_completed",
        "batch_saved"
    ]
    data: Dict
    timestamp: datetime = Field(default_factory=datetime.now)

# Example progress update:
{
  "type": "progress_update",
  "data": {
    "current_city": "Ä°stanbul",
    "current_district": "KadÄ±kÃ¶y", 
    "completed": 23,
    "total": 156,
    "percentage": 14.7,
    "eta": "45 minutes",
    "speed": "2.3 locations/min",
    "results_found": 1247
  },
  "timestamp": "2024-01-15T10:30:15Z"
}
```

### Live Log System
```python
class LogLevel(str, Enum):
    DEBUG = "DEBUG"
    INFO = "INFO" 
    WARNING = "WARNING"
    ERROR = "ERROR"
    SUCCESS = "SUCCESS"

class LogEntry(BaseModel):
    level: LogLevel
    message: str
    location: Optional[str] = None  # "Ä°stanbul/KadÄ±kÃ¶y"
    timestamp: datetime = Field(default_factory=datetime.now)
    details: Optional[Dict] = None  # Additional context

# Log message examples:
logs = [
    {
        "level": "INFO",
        "message": "Starting scrape for Ä°stanbul/KadÄ±kÃ¶y",
        "location": "Ä°stanbul/KadÄ±kÃ¶y",
        "timestamp": "2024-01-15T10:30:15Z"
    },
    {
        "level": "SUCCESS", 
        "message": "Found 15 dental clinics",
        "location": "Ä°stanbul/KadÄ±kÃ¶y",
        "details": {"places_found": 15, "search_method": "standard"},
        "timestamp": "2024-01-15T10:30:23Z"
    },
    {
        "level": "ERROR",
        "message": "API quota exceeded, retrying in 5 seconds",
        "location": "Ä°stanbul/BeÅŸiktaÅŸ", 
        "details": {"retry_attempt": 1, "max_retries": 3},
        "timestamp": "2024-01-15T10:30:45Z"
    }
]
```

## ğŸ’¾ Profile Management System

### Profile Storage Structure
```json
{
  "profiles": [
    {
      "id": "uuid-1",
      "name": "Major Cities - Standard Search",
      "description": "Quick scan of 15 major Turkish cities using standard search",
      "settings": {
        "api_key": "encrypted-key",
        "search_terms": ["diÅŸ kliniÄŸi", "dentist"],
        "default_radius": 15000,
        "request_delay": 1.0,
        "batch_size": 20,
        "storage_type": "json"
      },
      "locations": {
        "cities": {
          "Ä°stanbul": {
            "selected": true,
            "search_method": "standard",
            "city_level_search": true,
            "districts": {
              "KadÄ±kÃ¶y": {"selected": true, "search_method": "standard"},
              "BeÅŸiktaÅŸ": {"selected": true, "search_method": "grid"},
              "ÃœskÃ¼dar": {"selected": false, "search_method": "standard"}
            }
          },
          "Ankara": {
            "selected": true,
            "search_method": "standard", 
            "city_level_search": true,
            "districts": {}
          }
        }
      },
      "created_at": "2024-01-15T09:00:00Z",
      "last_used": "2024-01-15T10:30:00Z",
      "is_default": false
    }
  ],
  "settings": {
    "default_profile_id": "uuid-1",
    "auto_save_interval": 2,
    "last_backup": "2024-01-15T09:00:00Z"
  }
}
```

### Profile Operations
1. **Auto-save**: Save current configuration every 2 seconds (debounced)
2. **Manual save**: "Save as..." button to create new profile
3. **Load profile**: Select from dropdown to load saved configuration
4. **Export/Import**: JSON export for sharing configurations
5. **Backup**: Automatic daily backups of all profiles

### Preset Profiles
```javascript
const presetProfiles = [
  {
    name: "Quick Scan - Major Cities",
    description: "15 largest cities, city-level only, standard search",
    estimated_duration: "~2 hours",
    locations_count: 15,
    settings: {
      default_radius: 25000,
      search_method: "standard",
      city_level_only: true
    }
  },
  {
    name: "Detailed Istanbul",
    description: "All Istanbul districts with grid search",
    estimated_duration: "~6 hours", 
    locations_count: 39,
    settings: {
      default_radius: 5000,
      search_method: "grid",
      grid_settings: {width: 3, height: 3, radius: 500}
    }
  },
  {
    name: "Complete Turkey Scan",
    description: "All cities and districts, mixed methods",
    estimated_duration: "~48 hours",
    locations_count: 973,
    settings: {
      smart_method_selection: true,
      major_cities_grid: true,
      others_standard: true
    }
  }
]
```

## ğŸš€ API Endpoints

### Location Management
```python
# GET /api/locations
# Returns full location hierarchy with coordinates
{
  "cities": {
    "Ä°stanbul": {
      "coordinates": [41.0082, 28.9784],
      "districts": {
        "KadÄ±kÃ¶y": {"coordinates": [40.9903, 29.0205]},
        "BeÅŸiktaÅŸ": {"coordinates": [41.0441, 29.0017]}
      }
    }
  },
  "metadata": {
    "total_cities": 81,
    "total_districts": 973,
    "last_updated": "2024-01-15T00:00:00Z"
  }
}

# POST /api/locations/estimate
# Calculate estimated duration for given selection
{
  "locations": {...},
  "settings": {...}
}
# Returns:
{
  "estimated_duration": "2 hours 30 minutes",
  "total_locations": 45,
  "total_searches": 67,
  "estimated_results": "500-1500 places"
}
```

### Scraper Control
```python
# POST /api/scraper/start
{
  "profile_id": "uuid",
  "settings": {...},
  "locations": {...}
}

# POST /api/scraper/pause
# GET /api/scraper/status
# POST /api/scraper/stop

# GET /api/scraper/results
# Returns current results summary
{
  "total_found": 1247,
  "by_location": {
    "Ä°stanbul/KadÄ±kÃ¶y": 15,
    "Ä°stanbul/BeÅŸiktaÅŸ": 22
  },
  "last_updated": "2024-01-15T10:30:00Z"
}
```

### Profile Management  
```python
# GET /api/profiles
# POST /api/profiles (create new)
# PUT /api/profiles/{id} (update existing)
# DELETE /api/profiles/{id}
# POST /api/profiles/{id}/load (set as current)

# GET /api/profiles/presets
# Returns predefined profile templates
```

### Settings Management
```python
# GET /api/settings
# Returns current settings from settings.py

# PUT /api/settings
# Update settings (validates API key, etc.)

# POST /api/settings/test-api
# Test API key validity
{
  "api_key": "your-key"
}
# Returns:
{
  "valid": true,
  "quota_remaining": "95%",
  "daily_limit": 1000
}
```

## ğŸ”§ Implementation Phases

### Phase 1: Backend Foundation (Week 1)
1. **Project Setup**
   - Initialize FastAPI project structure
   - Set up CORS for React development
   - Create base models and database connections
   - Integrate with existing gmaps_scraper package

2. **Core API Endpoints**
   - Location hierarchy endpoint (`/api/locations`)
   - Basic settings CRUD (`/api/settings`)
   - Profile management (`/api/profiles`) 
   - API key validation (`/api/settings/test-api`)

3. **WebSocket Foundation**
   - WebSocket connection management
   - Basic message routing
   - Connection state handling

### Phase 2: Frontend Foundation (Week 2)
1. **React Project Setup**
   - Create React app with modern hooks
   - Set up routing and state management
   - Configure API client and WebSocket hooks
   - Implement responsive layout structure

2. **Core Components**
   - MainLayout (3-panel design)
   - Header with basic controls
   - Simple settings panel
   - Basic location tree (read-only)

3. **API Integration**
   - Connect to backend endpoints
   - Implement error handling
   - Add loading states

### Phase 3: Location Tree & Selection (Week 3)
1. **Advanced Tree Component**
   - Hierarchical city/district display
   - Checkbox states (checked/unchecked/mixed)
   - Expand/collapse functionality
   - Search method indicators

2. **Selection Logic**
   - Complex checkbox state management
   - Parent-child selection propagation
   - Search method assignment
   - Context menu implementation

3. **Batch Operations**
   - Smart selection presets
   - Mass action buttons
   - Bulk configuration changes

### Phase 4: Progress & Real-time Features (Week 4)
1. **WebSocket Integration**
   - Real-time progress updates
   - Live log streaming
   - Scraper control commands
   - Connection recovery

2. **Progress Dashboard**
   - Progress statistics display
   - ETA calculations
   - Results preview
   - Error tracking

3. **Scraper Integration**
   - Start/stop/pause controls
   - Configuration passing
   - Result retrieval
   - Error handling

### Phase 5: Profile System (Week 5)
1. **Profile Management**
   - CRUD operations for profiles
   - Auto-save implementation
   - Profile loading/switching
   - Backup/restore functionality

2. **Preset Profiles**
   - Predefined configuration templates
   - Quick setup options
   - Import/export functionality

3. **Settings Persistence**
   - Configuration validation
   - Settings synchronization
   - Default value management

### Phase 6: Polish & Testing (Week 6)
1. **UI/UX Improvements**
   - Responsive design refinements
   - Keyboard shortcuts
   - Accessibility improvements
   - Performance optimizations

2. **Testing & Documentation**
   - Unit tests for critical components
   - Integration testing
   - User documentation
   - Deployment guide

3. **Production Readiness**
   - Error monitoring
   - Logging improvements
   - Security considerations
   - Docker containerization

## ğŸ“‹ Success Criteria

### Functional Requirements
- âœ… Complete replacement of CLI functionality
- âœ… Intuitive location selection with visual feedback
- âœ… Real-time progress monitoring during scraping
- âœ… Profile-based configuration management
- âœ… All settings.py variables configurable via UI
- âœ… Batch operations for efficient setup
- âœ… Error handling and recovery

### Performance Requirements
- âœ… UI responsive under 200ms for all interactions
- âœ… WebSocket messages delivered under 100ms
- âœ… Tree view handles 1000+ locations smoothly
- âœ… Auto-save operations under 500ms
- âœ… Memory usage under 100MB for frontend

### Usability Requirements
- âœ… New users can start scraping within 5 minutes
- âœ… Complex configurations possible without documentation
- âœ… Clear visual feedback for all user actions
- âœ… Keyboard navigation support
- âœ… Mobile/tablet responsive design

## ğŸ” Technical Considerations

### Security
- API key encryption in profiles
- Input validation on all endpoints
- CORS configuration for production
- Rate limiting on API endpoints
- Secure WebSocket connections

### Scalability
- Efficient state management for large location trees
- Pagination for large result sets
- WebSocket connection pooling
- Profile storage optimization
- Background task queue for long operations

### Integration
- Seamless integration with existing scraper
- Backward compatibility with current data formats
- Migration path from CLI to UI
- Support for existing configuration files

### Browser Compatibility
- Modern browsers (Chrome 90+, Firefox 88+, Safari 14+)
- Progressive enhancement for older browsers
- Graceful degradation without JavaScript
- Mobile browser optimization

This plan provides a comprehensive roadmap for developing a modern, user-friendly web interface for the Google Maps Scraper project. The phased approach ensures steady progress while maintaining quality and usability standards.